{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# FineTuning [Nepali Casual LM](https://www.kaggle.com/datasets/reganmaharjan/nepali-trained-gpt2-casual-language-model) Model For Covid19 Related Headline Generator\n### Dataset used here is mixture [NepCov19News](https://www.kaggle.com/datasets/reganmaharjan/nepcov19news) and [NepCov19Tweets](https://www.kaggle.com/datasets/mathew11111/nepcov19tweets)\n\n### NepCov19News is collection of Covid Related News Headlines from 3 different News portals.\n**Note: Here I am using NepCov19Tweets as well because what can be observed is Tweets are often like a News headlines and summaries, making a statement and being informative in as few words as possible.**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nimport tensorflow as tf\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-26T10:32:04.691275Z","iopub.execute_input":"2023-05-26T10:32:04.691668Z","iopub.status.idle":"2023-05-26T10:32:07.305716Z","shell.execute_reply.started":"2023-05-26T10:32:04.691631Z","shell.execute_reply":"2023-05-26T10:32:07.304770Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/nepcov19news/NepCovNews.csv\n/kaggle/input/googletrans-augment-data/googletrans_augmented_data.csv\n/kaggle/input/nepali-trained-gpt2-casual-language-model/gpt2NepaliCasualLM/config.json\n/kaggle/input/nepali-trained-gpt2-casual-language-model/gpt2NepaliCasualLM/tf_model.h5\n/kaggle/input/nepali-trained-gpt2-casual-language-model/gpt2NepaliCasualLM/generation_config.json\n/kaggle/input/nepali-tokenizers/Nepali_Wordpiece.tokenizer\n/kaggle/input/nepali-tokenizers/Nepali_BPE.tokenizer\n/kaggle/input/preprocess-nepcov19tweets/__results__.html\n/kaggle/input/preprocess-nepcov19tweets/__resultx__.html\n/kaggle/input/preprocess-nepcov19tweets/__notebook__.ipynb\n/kaggle/input/preprocess-nepcov19tweets/__output__.json\n/kaggle/input/preprocess-nepcov19tweets/custom.css\n/kaggle/input/preprocess-nepcov19tweets/preprocess-nepcov19tweets/state.json\n/kaggle/input/preprocess-nepcov19tweets/preprocess-nepcov19tweets/dataset_info.json\n/kaggle/input/preprocess-nepcov19tweets/preprocess-nepcov19tweets/dataset.arrow\n/kaggle/input/preprocess-nepcov19tweets/__results___files/__results___12_1.png\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nimport datasets #huggingface datasets\n\ngt_aug_data = pd.DataFrame({'text':pd.read_csv(\"/kaggle/input/googletrans-augment-data/googletrans_augmented_data.csv\")['ne']})\nnep_cov_news_data = pd.read_csv(\"/kaggle/input/nepcov19news/NepCovNews.csv\")[['text']]\nnep_cov_tweets_data = pd.DataFrame({'text':datasets.Dataset.load_from_disk(\"/kaggle/input/preprocess-nepcov19tweets/preprocess-nepcov19tweets\")['Sentences']})\n\n# print(gt_aug_data.shape)\n# print(nep_cov_news_data.shape)\n# print(nep_cov_tweets_data.shape)\n\ndata = pd.concat([gt_aug_data,nep_cov_news_data,nep_cov_tweets_data])\ndata.drop_duplicates(inplace=True)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-05-26T10:32:07.307734Z","iopub.execute_input":"2023-05-26T10:32:07.308719Z","iopub.status.idle":"2023-05-26T10:32:07.942583Z","shell.execute_reply.started":"2023-05-26T10:32:07.308682Z","shell.execute_reply":"2023-05-26T10:32:07.941476Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"CPU times: user 543 ms, sys: 68 ms, total: 611 ms\nWall time: 615 ms\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                                    text\n0                             कोभिड भ्याक्सिन पनि लगाइयो\n1      रामेछापमा कोभिड–१९ सङ्क्रमितको सङ्ख्या ४८ पुगे...\n2      स्वास्थ्य मन्त्रालयले कोभिड–१९ को रोकथाम तथा न...\n3      कोभिड छ, अहिले पनि सामाजिक दूरी कायम गरेका छौं...\n4      संयुक्त राज्य अमेरिकाले कोभिड-१९ को मृत्युमा न...\n...                                                  ...\n33445  विश्व स्वास्थ्य संगठनले कोरोना भाइरसबाट हुने र...\n33449  कोरोना महामारी मंगलबारमात्रै जनाको मृत्यु औपचा...\n33458  कोभिड वारि सिन्धुपाल्चोक पुगेको जस्तो छ सरजी ए...\n33463  कोरोनाको न्वारानको नाम कोभिड विश्व स्वास्थ्य स...\n33465  कोरोना भाइरसको नाम कोभिड खोप बन्न डेढ वर्ष लाग्ने\n\n[50336 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>कोभिड भ्याक्सिन पनि लगाइयो</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>रामेछापमा कोभिड–१९ सङ्क्रमितको सङ्ख्या ४८ पुगे...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>स्वास्थ्य मन्त्रालयले कोभिड–१९ को रोकथाम तथा न...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>कोभिड छ, अहिले पनि सामाजिक दूरी कायम गरेका छौं...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>संयुक्त राज्य अमेरिकाले कोभिड-१९ को मृत्युमा न...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33445</th>\n      <td>विश्व स्वास्थ्य संगठनले कोरोना भाइरसबाट हुने र...</td>\n    </tr>\n    <tr>\n      <th>33449</th>\n      <td>कोरोना महामारी मंगलबारमात्रै जनाको मृत्यु औपचा...</td>\n    </tr>\n    <tr>\n      <th>33458</th>\n      <td>कोभिड वारि सिन्धुपाल्चोक पुगेको जस्तो छ सरजी ए...</td>\n    </tr>\n    <tr>\n      <th>33463</th>\n      <td>कोरोनाको न्वारानको नाम कोभिड विश्व स्वास्थ्य स...</td>\n    </tr>\n    <tr>\n      <th>33465</th>\n      <td>कोरोना भाइरसको नाम कोभिड खोप बन्न डेढ वर्ष लाग्ने</td>\n    </tr>\n  </tbody>\n</table>\n<p>50336 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = datasets.Dataset.from_pandas(data).remove_columns(column_names=['__index_level_0__'])\ndata = data.shuffle(999).train_test_split(test_size=0.002)\ngc.collect()\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2023-05-26T10:32:07.944007Z","iopub.execute_input":"2023-05-26T10:32:07.945800Z","iopub.status.idle":"2023-05-26T10:32:08.249514Z","shell.execute_reply.started":"2023-05-26T10:32:07.945762Z","shell.execute_reply":"2023-05-26T10:32:08.248525Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 50235\n    })\n    test: Dataset({\n        features: ['text'],\n        num_rows: 101\n    })\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"from tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom transformers import PreTrainedTokenizerFast\n\nprint(\"Initializing tokenizer as PreTrainedTokenizerFast\")\ntokenizer = PreTrainedTokenizerFast(tokenizer_object=Tokenizer(BPE()).from_file(\"/kaggle/input/nepali-tokenizers/Nepali_BPE.tokenizer\"))\ntokenizer.add_special_tokens({'pad_token': '[PAD]',\"eos_token\": \"[SEP]\", \"bos_token\":\"[CLS]\"})","metadata":{"execution":{"iopub.status.busy":"2023-05-26T10:32:08.252160Z","iopub.execute_input":"2023-05-26T10:32:08.252763Z","iopub.status.idle":"2023-05-26T10:32:08.456069Z","shell.execute_reply.started":"2023-05-26T10:32:08.252727Z","shell.execute_reply":"2023-05-26T10:32:08.454999Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Initializing tokenizer as PreTrainedTokenizerFast\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_function(rows):\n    return tokenizer(rows['text'])","metadata":{"execution":{"iopub.status.busy":"2023-05-26T10:32:08.457733Z","iopub.execute_input":"2023-05-26T10:32:08.458396Z","iopub.status.idle":"2023-05-26T10:32:08.464724Z","shell.execute_reply.started":"2023-05-26T10:32:08.458355Z","shell.execute_reply":"2023-05-26T10:32:08.463544Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(\"Tokenizing the data\")\ntokenized_inputs = data.map(\n    preprocess_function,\n    batched=True,\n    num_proc=4,\n    remove_columns=data[\"train\"].column_names,\n)\ntokenized_inputs = tokenized_inputs.remove_columns(['token_type_ids'])\ntokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2023-05-26T10:32:08.466232Z","iopub.execute_input":"2023-05-26T10:32:08.466859Z","iopub.status.idle":"2023-05-26T10:32:16.289482Z","shell.execute_reply.started":"2023-05-26T10:32:08.466794Z","shell.execute_reply":"2023-05-26T10:32:16.288444Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Tokenizing the data\n     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd1babea2e064e13aaa3688bdae364fd"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c71e62211558465491a7e26bf9f14685"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50e86eb59d5d4316a342e703023bc1ed"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"214e4cf50778477a9bfa6c6f80208a6e"}},"metadata":{}},{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a6b80462f9445f8cc43bcb3bbb47cd"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68d4c81176a043e0b4f498537c4f3d7f"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9b9e2dd46a5466c962cf096422b4004"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44cec7119c2548f69d9e5d3ac1b63861"}},"metadata":{}},{"name":"stdout","text":"CPU times: user 865 ms, sys: 703 ms, total: 1.57 s\nWall time: 7.81 s\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 50235\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 101\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"block_size = 128\n\ndef group_texts(rows):\n    # Concatenate all texts.\n    concatenated_rows = {k: sum(rows[k], []) for k in rows.keys()}\n    total_length = len(concatenated_rows[list(rows.keys())[0]])\n    remainder = total_length\n    \n    if total_length >= block_size:\n        total_length = (total_length // block_size) * block_size\n        remainder -=total_length\n        \n    # Split by chunks of block_size.\n    result = {\n        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n        for k, t in concatenated_rows.items()\n    }\n    \n    if(remainder):\n        for k in result.keys():\n            result[k].append(concatenated_rows[k][-128:])\n        \n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-05-26T10:32:16.291629Z","iopub.execute_input":"2023-05-26T10:32:16.292010Z","iopub.status.idle":"2023-05-26T10:32:16.300115Z","shell.execute_reply.started":"2023-05-26T10:32:16.291970Z","shell.execute_reply":"2023-05-26T10:32:16.299068Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"%%time\nprint(\"Grouping Tokens to Model Input Size\")\nlm_data = tokenized_inputs.map(group_texts, batched=True, num_proc=4)\nlm_data","metadata":{"execution":{"iopub.status.busy":"2023-05-26T10:32:16.301745Z","iopub.execute_input":"2023-05-26T10:32:16.302097Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Grouping Tokens to Model Input Size\n     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29217ef94b4a4b25a856d5d234e7127f"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3898a57477bb426a936241107b7bca45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"189c43bb316f426eb108a1b0e3a44a4e"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0c32c61e7e6468d9f598cfe38dc0c88"}},"metadata":{}},{"name":"stdout","text":"     ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"119b35064e86438b9962f222e65984c2"}},"metadata":{}},{"name":"stdout","text":"   ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95ac5a64bef04ac3b0e61ba5c3ee7649"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\nprint(\"Initializing Data Collator\")\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, \n                                                mlm=False, \n                                                return_tensors=\"tf\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TFAutoModelForCausalLM, AutoConfig\n\n## To change the size of embedding - N_EMBED must be properly divisible by the size N_HEAD value\n\nmodel = TFAutoModelForCausalLM.from_pretrained('/kaggle/input/nepali-trained-gpt2-casual-language-model/gpt2NepaliCasualLM',\n                                                n_head=12,\n                                                bos_token_id=tokenizer.bos_token_id,\n                                                eos_token_id=tokenizer.eos_token_id,\n                                                pad_token_id=tokenizer.pad_token_id,\n                                                id2label={0:\"NEUTRAL\",1:\"POSITIVE\",2:\"NEGATIVE\"},\n                                                label2id={\"NEUTRAL\":0,\"POSITIVE\":1,\"NEGATIVE\":2})\nmodel.resize_token_embeddings(len(tokenizer))\nprint(model.config)\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import create_optimizer, AdamWeightDecay\n\noptimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.001)\nmodel.compile(optimizer=optimizer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Preparing Training and Testing sets to TRAIN the MODEL\")\ntf_train_set = model.prepare_tf_dataset(\n    lm_data[\"train\"],\n    shuffle=True,\n    batch_size=16,\n    collate_fn=data_collator,\n)\n\ntf_test_set = model.prepare_tf_dataset(\n    lm_data[\"test\"],\n    shuffle=False,\n    batch_size=16,\n    collate_fn=data_collator,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the Model","metadata":{}},{"cell_type":"code","source":"%%time\n\nprint(\"Training the model\")\nhistory = model.fit(x=tf_train_set, \n          validation_data=tf_test_set,\n          epochs=10)\nmodel.save_pretrained(\"/kaggle/working/CovidNewsHeadlineGenerator\")\nprint(history.history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from seaborn import lineplot\nfrom matplotlib import pyplot as plt\n\nlineplot(history.history['loss'],)\nlineplot(history.history['val_loss'])\n\nplt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nmodel_pipeline = pipeline(\"text-generation\",model=model,tokenizer=tokenizer,framework='tf')\n\nmodel_pipeline([\"कोरोना संक्रमित भेटिएपछि\",\n                \"भारतमा एकै दिनमा कोभिड-१९ सङक्रमित\",\n                \"के मास्कले भाइरस\",\n                \"थपिए ४५ जना\",\n               \"स्वास्थ्य तथा जनसंख्या मन्त्रालयले\",\n                \"कोरोना नियन्त्रणमा स्थानीय\",\n                \"डेंगु संक्रमणबाट सिकिस्त\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token='')\nmodel.push_to_hub('raygx/Covid-News-Headline-Generator',commit_message=\"Finetuned raygx/GPT2-Nepali-Casual-LM model for generating Covid-News; 10 Epochs\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer.push_to_hub('raygx/Covid-News-Headline-Generator',commit_message='Uploading Tokenizer')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}