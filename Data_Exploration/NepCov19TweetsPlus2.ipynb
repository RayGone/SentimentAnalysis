{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "data = datasets.load_dataset('raygx/NepCov19TweetsPlus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(data['train'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['Sentences'])\n",
    "data['Sentiment'].value_counts(), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len'] = data.apply(lambda x: len(x['Sentences'].split(\" \")),axis=1)\n",
    "print(data['len'].value_counts())\n",
    "data[['len']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1\n",
    "**Removing rows with string length <= 5 words. Assumption is that they can't carry proper polarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[data['len']==1]['len'].value_counts())\n",
    "data[data['len']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['len']>1]\n",
    "data[['len']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[data['len']==2]['len'].value_counts())\n",
    "data[data['len']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['len']>2]\n",
    "data[['len']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[data['len']==3]['len'].value_counts())\n",
    "data[data['len']==3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2\n",
    "**Sentence Replication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['len']>5]\n",
    "data[['len']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sentiment'].value_counts(), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replication of short sentences instead of removing them\n",
    "def sentenceReplicator(row):\n",
    "    tlen = row['len']\n",
    "    \n",
    "    if tlen < 5:\n",
    "        row['Sentences'] = row['Sentences'] + \" [SEP] \" + row['Sentences'] + \" [SEP] \" + row['Sentences'] \n",
    "    else:\n",
    "        row['Sentences'] = row['Sentences'] + \" [SEP] \" + row['Sentences']\n",
    "    \n",
    "    return row['Sentences']    \n",
    "\n",
    "\n",
    "data['Sentences'] = data.apply(lambda x: x['Sentences'] if x['len']>9 else sentenceReplicator(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len'] = data.apply(lambda x: len(x['Sentences'].split(\" \")),axis=1)\n",
    "print(data['len'].value_counts())\n",
    "data.describe() , data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Phase\n",
    "**Push To Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushToHub(data,dataset_name = 'raygx/NepCov19TweetsPlus2',token = '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'):\n",
    "    data = datasets.Dataset.from_pandas(data)\n",
    "    data = data.remove_columns('__index_level_0__')\n",
    "    data = data.remove_columns('len')\n",
    "    print(data)\n",
    "    \n",
    "    # login require python > 3.9 \n",
    "    from huggingface_hub import login\n",
    "    login(token)\n",
    "\n",
    "    data.push_to_hub(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pushToHub(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
