# -*- coding: utf-8 -*-
"""NepCov19Tweets- Sentiment Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tox6b2b-pgk3zgLSuAOFnii3K3LCX6d8
"""

# !pip install transformers datasets tokenizers evaluate huggingface_hub --quiet

import numpy as np

# from huggingface_hub import login
# login( token: typing.Optional[str] = Noneadd_to_git_credential: bool = Falsenew_session: bool = Truewrite_permission: bool = False ) ()

"""# Loading Model and Tokenizer"""

from transformers import TFAutoModelForSequenceClassification, PreTrainedTokenizerFast
import datasets

tokenizer = PreTrainedTokenizerFast.from_pretrained('raygx/GPT2-NepSA-T1')
tokenizer

from transformers import AutoConfig
from transformers import BertTokenizerFast

using = 'gpt' # Model to use
use_config = False # When True initializes the model with random weights and when true initilizes the model with pretrained weigths

if using == 'gpt':
  config = AutoConfig.from_pretrained(
            'raygx/GPT2-Nepali-Casual-LM',
            bos_token_id=tokenizer.bos_token_id,
            eos_token_id=tokenizer.eos_token_id,
            pad_token_id=tokenizer.pad_token_id,
            id2label={0:"NEUTRAL",1:"POSITIVE",2:"NEGATIVE"},
            label2id={"NEUTRAL":0,"POSITIVE":1,"NEGATIVE":2}
          )
  
  print("Loading Model 'distilGPT2")
  if use_config:
    print("Intialization: New")
    model = TFAutoModelForSequenceClassification.from_config(config)
  else:    
    print("Intialization: Pretrained - raygx/GPT2-Nepali-Casual-LM")
    model = TFAutoModelForSequenceClassification.from_pretrained('raygx/GPT2-Nepali-Casual-LM',config = config)
  
if using == 'bert':  
  config = AutoConfig.from_pretrained(
            'distilbert-base-uncased',
            bos_token_id=tokenizer.bos_token_id,
            eos_token_id=tokenizer.eos_token_id,
            pad_token_id=tokenizer.pad_token_id,
            id2label={0:"NEUTRAL",1:"POSITIVE",2:"NEGATIVE"},
            label2id={"NEUTRAL":0,"POSITIVE":1,"NEGATIVE":2}
          )
  
  print("Loading Model 'distilbert-base-uncased")
  if use_config:
    print("Intialization: New")
    model = TFAutoModelForSequenceClassification.from_config(config)
  else:
    print("Intialization: Pretrained")
    model = TFAutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased',config = config)

  tokenizer = BertTokenizerFast.from_pretrained("raygx/GPT2-Nepali-Casual-LM")
  
model.resize_token_embeddings(len(tokenizer))

print(model.config)
print(model.summary())

from transformers import create_optimizer, AdamWeightDecay
import tensorflow as tf

optimizer = AdamWeightDecay(learning_rate=5e-6, weight_decay_rate=0.001)
model.compile(optimizer=optimizer)
"""# Data Loading and Preparation"""

data = datasets.load_dataset("raygx/NepCov19Tweets",split='train').select(range(1000))
data = data.rename_columns({"Sentiment":"labels","Sentences":"text"})
data

data = data.shuffle(999)
data = data.train_test_split(test_size=0.2)
data

def prepareLabels(row):
    if row['labels'] == -1:
        row['labels'] = 2
        
    return row

data = data.map(
        prepareLabels,
        num_proc=4)

print(data)

print("here i am")
exit()

def preprocess_function(rows):
    return tokenizer(rows['text'],truncation=True)

print("Tokenizing the data")
tokenized_inputs = data.map(
    preprocess_function,
    batched=True,
    num_proc=2,
    remove_columns=data["train"].column_names,
)
tokenized_inputs = tokenized_inputs.remove_columns(['token_type_ids'])

tokenized_inputs['train'] = tokenized_inputs['train'].add_column(
    name="labels",column=data['train']['labels']
)
tokenized_inputs['test'] = tokenized_inputs['test'].add_column(
    name="labels",column=data['test']['labels']
)

tokenized_inputs

print(data['train'][:1])
print(tokenized_inputs['train'][:1]['input_ids'])
print(tokenizer.batch_decode(tokenized_inputs['train'][:1]['input_ids']))

from transformers import DataCollatorWithPadding

print("Initializing Data Collator")
data_collator = DataCollatorWithPadding(tokenizer=tokenizer, 
                                        max_length=128,
                                        return_tensors="tf")

print("Preparing Training and Testing sets to TRAIN the MODEL")
tf_train_set = model.prepare_tf_dataset(
    tokenized_inputs["train"],
    shuffle=True,
    batch_size=16,
    collate_fn=data_collator,
)

tf_test_set = model.prepare_tf_dataset(
    tokenized_inputs["test"],
    shuffle=False,
    batch_size=16,
    collate_fn=data_collator,
)

"""# Training and Evaluation

## Training **Batch 1**
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# n_epoch = 5
# print("Training the model")
# history = model.fit(x=tf_train_set, 
#           validation_data=tf_test_set,
#           epochs=n_epoch)
# print(history.history)

import seaborn

seaborn.lineplot(history.history['loss'])
seaborn.lineplot(history.history['val_loss'])

"""### Evaluation"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from transformers import pipeline, TextClassificationPipeline
# 
# if using=='gpt':
#   print("Getting Test Prediction")
#   pipe = pipeline('sentiment-analysis',model=model,tokenizer=tokenizer,device=1)
#   prediction = pipe(data['test']['text'])
# 
#   print("Prediction Label to Id")
#   pred_labels = [model.config.label2id[x['label']] for x in prediction]
# else:  
#   print("Getting Test Prediction")
#   pred_labels = [np.argmax(tf.nn.softmax(model(tf.constant(x)).logits)) for x in tokenized_inputs['test']['input_ids']]
# 
# actual_labels = data['test']['labels']

"""**Computing F1-Score, Precision, Recall and Accuracy of the Model**"""

from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score

print("F1-Score",f1_score(actual_labels,pred_labels,average='weighted'))
print("Precision-Score",precision_score(actual_labels,pred_labels,average='weighted'))
print("Recall-Score",recall_score(actual_labels,pred_labels,average='weighted'))
print("accuracy_Score",accuracy_score(actual_labels,pred_labels))

"""**Plotting Confusion Matrix**"""

from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

cmd = ConfusionMatrixDisplay(tf.math.confusion_matrix(actual_labels,pred_labels,num_classes=3).numpy())
cmd.plot()

"""**Pushing Model to Huggingface Hub**"""

### Pushing Model to hub
# if using=='gpt':
#   model.push_to_hub("raygx/GPT2-NepSA-T1",commit_message="Training From Scratch:Distilgpt2;3L4H:Batch 1:Epoch 20; lr=2e-6")

1/0

"""## Training **Batch 2**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# n_epoch = 5
# print("Training the model")
# history = model.fit(x=tf_train_set, 
#           validation_data=tf_test_set,
#           epochs=n_epoch)
# print(history.history)

import seaborn

seaborn.lineplot(history.history['loss'])
seaborn.lineplot(history.history['val_loss'])

"""### Evaluation"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from transformers import pipeline, TextClassificationPipeline
# 
# if using=='gpt':
#   def batchPrediction(rows):
#     pass
# 
#   print("Getting Test Prediction")
#   pipe = pipeline('sentiment-analysis',model=model,tokenizer=tokenizer,device=1)
#   prediction = pipe(data['test']['text'])
# 
#   print("Prediction Label to Id")
#   pred_labels = [model.config.label2id[x['label']] for x in prediction]
# else:  
#   print("Getting Test Prediction")
#   pred_labels = [np.argmax(tf.nn.softmax(model(tf.constant(x)).logits)) for x in tokenized_inputs['test']['input_ids']]
# 
# actual_labels = data['test']['labels']

"""**Computing F1-Score, Precision, Recall and Accuracy of the Model**"""

from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score

print("F1-Score",f1_score(actual_labels,pred_labels,average='weighted'))
print("Precision-Score",precision_score(actual_labels,pred_labels,average='weighted'))
print("Recall-Score",recall_score(actual_labels,pred_labels,average='weighted'))
print("accuracy_Score",accuracy_score(actual_labels,pred_labels))

"""**Plotting Confusion Matrix**"""

from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt

cmd = ConfusionMatrixDisplay(tf.math.confusion_matrix(actual_labels,pred_labels,num_classes=3).numpy())
cmd.plot()

"""**Pushing Model to Huggingface Hub**"""

# tokenizer.push_to_hub("raygx/GPT2-NepSA-T1")

### Pushing Model to hub
# if using=='gpt':
#   model.push_to_hub("raygx/GPT2-NepSA-T1",commit_message="Training From Scratch:Distilgpt2;3L4H:Batch 1:Epoch 40")

